{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "# Simulation parameters\n",
    "n_simulations = 10**4  # Number of simulations to approximate the distribution\n",
    "beta = 10**8  # Inverse temperature\n",
    "lambda_step = 10**(-4)  # Step size for SGLD\n",
    "gamma = 10**(-8)  # Regularization parameter\n",
    "theta = 0  # Initial guess for theta\n",
    "\n",
    "# Set quantile levels and number of iterations for SGLD\n",
    "q = 0.95\n",
    "n_iterations = 10**5\n",
    "n_assets = 3  # Number of assets in the portfolio\n",
    "# Define the initial weights for the portfolio\n",
    "initial_weights = np.array([1.0 / n_assets] * n_assets)\n",
    "\n",
    "# Asset parameters for each scenario\n",
    "\n",
    "asset_params = [\n",
    "    [{'mu': 500, 'sigma': 1}, {'mu': 0, 'sigma': 10**6}, {'mu': 0, 'sigma': 10**-4}],\n",
    "    [{'mu': 500, 'sigma': 1}, {'mu': 0, 'sigma': 10**6}, {'mu': 0, 'sigma': 1}],\n",
    "    [{'mu': 0, 'sigma': 10**3}, {'mu': 0, 'sigma': 1}, {'mu': 0, 'sigma': 4}],\n",
    "    [{'mu': 0, 'sigma': 1}, {'mu': 1, 'sigma': 4}, {'mu': 0, 'sigma': 10**-4}],\n",
    "    [{'mu': 0, 'sigma': 1}, {'mu': 1, 'sigma': 4}, {'mu': 2, 'sigma': 1}]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def softmax(weights):\n",
    "    \"\"\"Compute softmax values for each set of scores in x.\"\"\"\n",
    "    e_w = np.exp(weights - np.max(weights))\n",
    "    return e_w / e_w.sum()\n",
    "\n",
    "def softmax_derivative(w, j):\n",
    "    \"\"\"Calculate the softmax derivative for weight index j with respect to all weights.\"\"\"\n",
    "    exp_weights = np.exp(w)\n",
    "    sum_exp_weights = np.sum(exp_weights)\n",
    "    \n",
    "    # Initialize an array for the derivatives\n",
    "    derivative = np.zeros_like(w)\n",
    "    \n",
    "    # Compute the derivative for each weight i with respect to weight j\n",
    "    for i in range(len(w)):\n",
    "        if i == j:\n",
    "            derivative[i] = exp_weights[j] * (sum_exp_weights - exp_weights[j]) / sum_exp_weights**2\n",
    "        else:\n",
    "            derivative[i] = -exp_weights[i] * exp_weights[j] / sum_exp_weights**2\n",
    "    \n",
    "    return derivative\n",
    "\n",
    "def simulate_asset_returns(mu, sigma, size):\n",
    "    # Simulate asset returns with truncation to limit extreme values\n",
    "    return np.clip(np.random.normal(mu, sigma, size), mu - 3*sigma, mu + 3*sigma)\n",
    "\n",
    "def calculate_portfolio_return(weights, returns):\n",
    "    \"\"\"Calculate the weighted sum of returns.\"\"\"\n",
    "    return np.dot(returns, weights)\n",
    "\n",
    "# Placeholder for the loss function V(theta)\n",
    "def V(theta, returns, q, gamma):\n",
    "    loss = np.mean([theta + (1/(1 - q)) * max(return_ - theta, 0) for return_ in returns]) + gamma * theta**2\n",
    "    return loss\n",
    "\n",
    "def calculate_loss(theta, weights, returns, q, gamma):\n",
    "    \"\"\"Calculate the loss function for CVaR optimization.\"\"\"\n",
    "    loss = np.mean([theta + (1/(1 - q)) * max(np.dot(return_ , weights)- theta, 0) for return_ in returns]) + gamma * theta**2\n",
    "    return loss\n",
    "\n",
    "def H_theta(theta, weights, returns, q, gamma):\n",
    "    \"\"\"Compute the gradient with respect to theta.\"\"\"\n",
    "    portfolio_return = calculate_portfolio_return(weights, returns)\n",
    "    indicator = (portfolio_return >= theta).astype(float)\n",
    "    return 1 - np.mean(indicator) / (1 - q) + 2 * gamma * theta\n",
    "\n",
    "def H_weights(theta, weights, returns, q, gamma):\n",
    "    \"\"\"Compute the gradient with respect to the portfolio weights.\"\"\"\n",
    "    n_assets = len(weights)\n",
    "    soft_weights = softmax(weights)\n",
    "    \n",
    "    # Compute portfolio returns\n",
    "    portfolio_returns = calculate_portfolio_return(soft_weights, returns)\n",
    "    \n",
    "    # Compute indicator for whether each simulation's return is below theta\n",
    "    indicator = (portfolio_returns >= theta).astype(float)\n",
    "\n",
    "    # Initialize the gradient vector for weights\n",
    "    grad_w = np.zeros(n_assets)\n",
    "\n",
    "    # Compute gradients for all weights\n",
    "    for j in range(n_assets):\n",
    "        # Compute derivative of the softmax for weight j\n",
    "        derivative = softmax_derivative(weights, j)\n",
    "        \n",
    "        # Sum the contributions to the gradient from all simulations\n",
    "        for i in range(returns.shape[0]):  # Iterate over simulations\n",
    "            grad_contribution = derivative * (returns[i] - theta) * indicator[i]\n",
    "            grad_w[j] += np.sum(grad_contribution) / (1 - q)\n",
    "        \n",
    "        # Add regularization term\n",
    "        grad_w[j] += 2 * gamma * weights[j]\n",
    "\n",
    "    return grad_w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面是更新 SGLD 步骤的函数\n",
    "def sgld_step(theta, weights, returns, q, gamma, lambda_step, beta):\n",
    "    # Assuming returns is of shape (n_simulations, n_assets) and weights is of shape (n_assets,)\n",
    "    theta_grad = H_theta(theta, weights, returns, q, gamma)\n",
    "    weights_grad = H_weights(theta, weights, returns, q, gamma)\n",
    "\n",
    "    # SGLD update for theta\n",
    "    theta += -lambda_step * theta_grad + np.sqrt(2 * lambda_step / beta) * np.random.randn()\n",
    "    #theta = max(theta, 0)  # Ensure theta is non-negative\n",
    "\n",
    "    # SGLD update for weights\n",
    "    weights += -lambda_step * weights_grad + np.sqrt(2 * lambda_step / beta) * np.random.randn(len(weights))\n",
    "    weights = softmax(weights)  # Normalizing the weights after update\n",
    "    return theta, weights\n",
    "\n",
    "def run_sgld_simulation(asset_params, q, lambda_step, gamma, n_iterations, n_simulations, n_assets, beta):\n",
    "    theta = 0  # Initial random value for theta\n",
    "    weights = np.array([1.0 / n_assets] * n_assets)  # Initial random weights for assets\n",
    "    returns = np.array([simulate_asset_returns(param['mu'], param['sigma'], n_simulations) for param in asset_params]).T\n",
    "    for _ in range(n_iterations):\n",
    "        # Generate returns for each asset ensuring the shape is (n_simulations, n_assets)\n",
    "        \n",
    "        # Update theta and weights using SGLD step\n",
    "        theta, weights = sgld_step(theta, weights, returns, q, gamma, lambda_step, beta)\n",
    "    # returns = np.array([simulate_asset_returns(param['mu'], param['sigma'], n_simulations) for param in asset_params]).T\n",
    "    # Calculate the final CVaR using the optimized parameters\n",
    "    cvar = calculate_loss(theta, weights, returns, q, gamma)\n",
    "    return weights, theta, cvar\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Optimized Weights  VaR_SGLD  CVaR_SGLD\n",
      "0                                    [0.0, 0.0, 1.0]  0.000195   0.000214\n",
      "1                                    [0.0, 0.0, 1.0]  1.667045   2.070490\n",
      "2                 [0.0, 1.0, 1.412304749076238e-277]  1.624726   2.033299\n",
      "3  [0.007926618503738074, 1.341881121654952e-06, ...  0.013067   0.016502\n",
      "4  [0.9688457227275914, 0.0025036704027919477, 0....  1.693397   2.082974\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = []\n",
    "for scenario_params in asset_params:\n",
    "    optimized_weights, VaR, CVaR = run_sgld_simulation(scenario_params, q, lambda_step, gamma, n_iterations, n_simulations, n_assets, beta)\n",
    "    results.append({\n",
    "        'Optimized Weights': optimized_weights,\n",
    "        'VaR_SGLD': VaR,\n",
    "        'CVaR_SGLD': CVaR\n",
    "    })\n",
    "\n",
    "# You can then convert these results to a DataFrame for display similar to the table in your images\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
