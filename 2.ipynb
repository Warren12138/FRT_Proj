{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Simulation parameters\n",
    "n_simulations = 10**4  # Number of simulations to approximate the distribution\n",
    "beta = 10**8  # Inverse temperature\n",
    "lambda_step = 10**(-4)  # Step size for SGLD\n",
    "gamma = 10**(-8)  # Regularization parameter\n",
    "#theta = 0  # Initial guess for theta\n",
    "\n",
    "# Set quantile levels and number of iterations for SGLD\n",
    "q = 0.95\n",
    "n_iterations = 10**6\n",
    "n_assets = 3  # Number of assets in the portfolio\n",
    "# Define the initial weights for the portfolio\n",
    "initial_weights = np.array([1.0 / n_assets] * n_assets)\n",
    "\n",
    "# Asset parameters for each scenario\n",
    "\n",
    "asset_params = [\n",
    "    [{'mu': 500, 'sigma': 1}, {'mu': 0, 'sigma': 10**6}, {'mu': 0, 'sigma': 10**-4}],\n",
    "    [{'mu': 500, 'sigma': 1}, {'mu': 0, 'sigma': 10**6}, {'mu': 0, 'sigma': 1}],\n",
    "    [{'mu': 0, 'sigma': 10**3}, {'mu': 0, 'sigma': 1}, {'mu': 0, 'sigma': 4}],\n",
    "    [{'mu': 0, 'sigma': 1}, {'mu': 1, 'sigma': 4}, {'mu': 0, 'sigma': 10**-4}],\n",
    "    [{'mu': 0, 'sigma': 1}, {'mu': 1, 'sigma': 4}, {'mu': 2, 'sigma': 1}]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([500.42836796, 499.49379377, 499.45993278, ..., 501.10083044,\n",
      "       498.424526  , 499.66569343]), array([ -362509.73310171, -1395875.16020609, -1184788.09751686, ...,\n",
      "        -485762.56052776, -2042933.83435082,  -101307.65994096]), array([-7.50985438e-05, -1.09046429e-04,  1.29986612e-04, ...,\n",
      "        1.66693109e-04,  3.54178889e-05,  1.03680841e-05])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Simulate asset returns\n",
    "def simulate_asset_returns(params, size):\n",
    "    return [np.random.normal(asset['mu'], asset['sigma'], size) for asset in params]\n",
    "print(simulate_asset_returns(asset_params[0],10000))\n",
    "# Generate asset returns\n",
    "def simulate_asset_returns_1(mu, sigma, size):\n",
    "    return np.random.normal(mu, sigma, size)\n",
    "\n",
    "# Calculate VaR and CVaR from simulated returns\n",
    "def calculate_var_cvar(returns, q):\n",
    "    var = np.quantile(returns, q)\n",
    "    # Sort returns\n",
    "    sorted_returns = np.sort(returns)\n",
    "    # Find the index where VaR would be positioned in the sorted list\n",
    "    var_index = np.searchsorted(sorted_returns, var, side='right')\n",
    "    # CVaR is the average of the worst 1-q percent of returns\n",
    "    cvar = np.mean(sorted_returns[var_index:])\n",
    "    return var, cvar\n",
    "\n",
    "# Calculate VaR and CVaR from simulated returns\n",
    "def calculate_var_cvar_1(returns, q):\n",
    "    var = np.quantile(returns, q)\n",
    "    # Sort returns\n",
    "    sorted_returns = np.sort(returns)\n",
    "    # Find the index where VaR would be positioned in the sorted list\n",
    "    var_index = np.searchsorted(sorted_returns, var, side='right')\n",
    "    # CVaR is the average of the worst 1-q percent of returns\n",
    "    cvar = np.mean(sorted_returns[var_index:])\n",
    "    return  var\n",
    "# Calculate VaR and CVaR from simulated returns\n",
    "def calculate_var_cvar_2(returns, q):\n",
    "    var = np.quantile(returns, q)\n",
    "    # Sort returns\n",
    "    sorted_returns = np.sort(returns)\n",
    "    # Find the index where VaR would be positioned in the sorted list\n",
    "    var_index = np.searchsorted(sorted_returns, var, side='right')\n",
    "    # CVaR is the average of the worst 1-q percent of returns\n",
    "    cvar = np.mean(sorted_returns[var_index:])\n",
    "    return  cvar\n",
    "\n",
    "def V(theta_hat, weights, q, gamma, params):\n",
    "    X = simulate_asset_returns(params, 1)\n",
    "    # Calculate the positive part of returns - theta\n",
    "    portfolio_losses = ((np.sum(np.exp(weights) * X))/ (np.sum(np.exp(weights)))) - theta_hat\n",
    "    return np.mean(np.maximum(portfolio_losses,0)/(1 - q) + theta_hat) + gamma * np.abs(theta_hat)**2 \n",
    "\n",
    "\n",
    "def partial_g_w(weights, params, j):\n",
    "    sum_exp_weights = np.sum(np.exp(weights))\n",
    "    g_w = np.zeros_like(weights)\n",
    "    X = np.array(simulate_asset_returns(params, 1))\n",
    "    for i in range(len(weights)):\n",
    "        if i != j:\n",
    "            g_w[i] = -np.sum(X * (np.exp(weights[i]) * np.exp(weights[j])) / sum_exp_weights**2)\n",
    "        else:\n",
    "            g_w[i] = np.sum(X * ((sum_exp_weights - np.exp(weights[i])) - np.exp(weights[i])) / sum_exp_weights**2)\n",
    "    return np.sum(g_w)\n",
    "\n",
    "def H_theta(theta_hat, weights, params, q, gamma):\n",
    "    X = np.array(simulate_asset_returns(params, 1))\n",
    "    portfolio_losses = ((np.sum(np.exp(weights) * X))/ (np.sum(np.exp(weights)))) - theta_hat\n",
    "    # Filter for positive losses\n",
    "    positive_losses = portfolio_losses > 0\n",
    "    # Calculate the average loss where the condition is True\n",
    "    loss = np.mean(portfolio_losses[positive_losses]) if np.any(positive_losses) else 0\n",
    "    # Regularization term\n",
    "    regularization = 2 * gamma * theta_hat**2\n",
    "    # The complete loss is the sum of the two terms\n",
    "    return 1 - (1/(1 - q)) * loss + regularization\n",
    "\n",
    "def H_wj(theta_hat, weights, params,j, q, gamma):\n",
    "    X = np.array(simulate_asset_returns(params, 1))\n",
    "    portfolio_losses = ((np.sum(np.exp(weights) * X))/ (np.sum(np.exp(weights)))) - theta_hat\n",
    "    # Filter for positive losses\n",
    "    positive_losses = portfolio_losses > 0\n",
    "    # Calculate the average loss where the condition is True\n",
    "    loss = np.mean(portfolio_losses[positive_losses]) if np.any(positive_losses) else 0\n",
    "    return (1/(1 - q)) * partial_g_w(weights, params, j) * loss + 2 * gamma * weights[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 1:\n",
      "Optimal weights: (0.0, 0.0, 1.0)\n",
      "Minimum VaR: 501.62836934976275\n",
      "Minimum CVaR: 0.000206419283677028\n",
      "Scenario 2:\n",
      "Optimal weights: (0.0, 0.0, 1.0)\n",
      "Minimum VaR: 501.6647265862163\n",
      "Minimum CVaR: 2.077807121129769\n",
      "Scenario 3:\n",
      "Optimal weights: (0.0, 0.9473684210526315, 0.052631578947368474)\n",
      "Minimum VaR: 1640.9717869195256\n",
      "Minimum CVaR: 1.9679162853010606\n",
      "Scenario 4:\n",
      "Optimal weights: (0.0, 0.0, 1.0)\n",
      "Minimum VaR: 1.65001915951139\n",
      "Minimum CVaR: 0.000205476218005448\n",
      "Scenario 5:\n",
      "Optimal weights: (1.0, 0.0, 0.0)\n",
      "Minimum VaR: 1.678568982788096\n",
      "Minimum CVaR: 2.0020663464542436\n"
     ]
    }
   ],
   "source": [
    "# Initialize the minimum CVaR to a large number\n",
    "min_cvar = float('inf')\n",
    "\n",
    "# Define a function to find optimal weights for a given scenario\n",
    "def find_optimal_weights(scenario):\n",
    "    global min_cvar\n",
    "    min_cvar = float('inf')\n",
    "    optimal_weights = None\n",
    "    # Create a grid of weight combinations to search\n",
    "    for w1 in np.linspace(0, 1, 20):\n",
    "        for w2 in np.linspace(0, 1 - w1, 20):\n",
    "            w3 = 1 - w1 - w2\n",
    "            returns_X1 = simulate_asset_returns_1(scenario[0]['mu'], scenario[0]['sigma'], n_simulations)\n",
    "            returns_X2 = simulate_asset_returns_1(scenario[1]['mu'], scenario[1]['sigma'], n_simulations)\n",
    "            returns_X3 = simulate_asset_returns_1(scenario[2]['mu'], scenario[2]['sigma'], n_simulations)\n",
    "            portfolio_returns = w1 * returns_X1 + w2 * returns_X2 + w3 * returns_X3\n",
    "            cvar = calculate_var_cvar_2(portfolio_returns, q)\n",
    "            if cvar < min_cvar:\n",
    "                min_cvar = cvar\n",
    "                optimal_weights = (w1, w2, w3)\n",
    "    return optimal_weights, min_cvar ,calculate_var_cvar_1(portfolio_returns, q)\n",
    "\n",
    "# Iterate over each scenario to find the optimal weights and CVaR\n",
    "optimal_weights_all_scenarios = []\n",
    "min_cvar_all_scenarios = []\n",
    "var_all = []\n",
    "\n",
    "for scenario in asset_params:\n",
    "    optimal_weights, min_cvar, min_var = find_optimal_weights(scenario)\n",
    "    optimal_weights_all_scenarios.append(optimal_weights)\n",
    "    min_cvar_all_scenarios.append(min_cvar)\n",
    "    var_all.append(min_var)\n",
    "\n",
    "# Display the results\n",
    "for i, (weights, var, cvar) in enumerate(zip(optimal_weights_all_scenarios, var_all, min_cvar_all_scenarios)):\n",
    "    print(f\"Scenario {i+1}:\")\n",
    "    print(f\"Optimal weights: {weights}\")\n",
    "    print(f\"Minimum VaR: {var}\")\n",
    "    print(f\"Minimum CVaR: {cvar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Run the optimization for each scenario\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m scenario_params \u001b[38;5;129;01min\u001b[39;00m asset_params:\n\u001b[0;32m---> 34\u001b[0m     optimized_weights, VaR, CVaR \u001b[38;5;241m=\u001b[39m sgld_optimization(\n\u001b[1;32m     35\u001b[0m         scenario_params, q, gamma, lambda_step, n_iterations, beta\n\u001b[1;32m     36\u001b[0m     )\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimized weights: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimized_weights\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue at Risk (VaR): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mVaR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[73], line 8\u001b[0m, in \u001b[0;36msgld_optimization\u001b[0;34m(params, q, gamma, lambda_step, n_iterations, beta)\u001b[0m\n\u001b[1;32m      5\u001b[0m initial_weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m n_assets] \u001b[38;5;241m*\u001b[39m n_assets)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iterations):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# portfolio_returns = np.dot(weights, asset_returns)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     returns \u001b[38;5;241m=\u001b[39m simulate_asset_returns(params, n_simulations) \n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#portfolio_returns = calculate_var_cvar(returns, q)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m#portfolio_returns = np.dot(weights, returns)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Calculate the gradient for theta and update it\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     theta_gradient \u001b[38;5;241m=\u001b[39m H_theta(theta[\u001b[38;5;241m0\u001b[39m], initial_weights, params, q, gamma)\n",
      "Cell \u001b[0;32mIn[71], line 3\u001b[0m, in \u001b[0;36msimulate_asset_returns\u001b[0;34m(params, size)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimulate_asset_returns\u001b[39m(params, size):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(asset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmu\u001b[39m\u001b[38;5;124m'\u001b[39m], asset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigma\u001b[39m\u001b[38;5;124m'\u001b[39m], size) \u001b[38;5;28;01mfor\u001b[39;00m asset \u001b[38;5;129;01min\u001b[39;00m params]\n",
      "Cell \u001b[0;32mIn[71], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimulate_asset_returns\u001b[39m(params, size):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(asset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmu\u001b[39m\u001b[38;5;124m'\u001b[39m], asset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigma\u001b[39m\u001b[38;5;124m'\u001b[39m], size) \u001b[38;5;28;01mfor\u001b[39;00m asset \u001b[38;5;129;01min\u001b[39;00m params]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# The main SGLD optimization routine\n",
    "def sgld_optimization(params, q, gamma, lambda_step, n_iterations, beta):\n",
    "    # Initialize theta and weights\n",
    "    theta = np.zeros(n_assets + 1)\n",
    "    initial_weights = np.array([1.0 / n_assets] * n_assets)\n",
    "    for _ in range(n_iterations):\n",
    "        # portfolio_returns = np.dot(weights, asset_returns)\n",
    "        returns = simulate_asset_returns(params, n_simulations) \n",
    "        #portfolio_returns = calculate_var_cvar(returns, q)\n",
    "        #portfolio_returns = np.dot(weights, returns)\n",
    "        # Calculate the gradient for theta and update it\n",
    "        theta_gradient = H_theta(theta[0], initial_weights, params, q, gamma)\n",
    "        theta[0] -= lambda_step * theta_gradient + np.sqrt(2 * lambda_step / beta) * np.random.randn()\n",
    "\n",
    "        # Calculate the gradient for each weight and update them\n",
    "        for j in range(len(initial_weights)):\n",
    "            wj_gradient = H_wj(theta[0], initial_weights, params, j, q, gamma)\n",
    "            #weights[j] -= lambda_step * wj_gradient + np.sqrt(2 * lambda_step / beta) * np.random.randn()\n",
    "            theta[j+1] -= lambda_step * wj_gradient + np.sqrt(2 * lambda_step / beta) * np.random.randn()\n",
    "        \n",
    "        # theta -= lambda_step * (theta_gradient, wj_gradient) + np.sqrt(2 * lambda_step / beta) * np.random.randn()\n",
    "\n",
    "        # Re-normalize weights after update\n",
    "        initial_weights /= np.sum(initial_weights)\n",
    "      \n",
    "    # Calculate the portfolio's VaR and CVaR using the optimized weights and theta\n",
    "    VaR_SGLD = theta\n",
    "    CVaR_SGLD = V(theta, initial_weights, q, gamma, params)  # This would typically use theta to calculate VaR_SGLD, CVaR_SGLD\n",
    "    \n",
    "    return initial_weights, VaR_SGLD, CVaR_SGLD\n",
    "\n",
    "# Run the optimization for each scenario\n",
    "for scenario_params in asset_params:\n",
    "    optimized_weights, VaR, CVaR = sgld_optimization(\n",
    "        scenario_params, q, gamma, lambda_step, n_iterations, beta\n",
    "    )\n",
    "    print(f\"Optimized weights: {optimized_weights}\")\n",
    "    print(f\"Value at Risk (VaR): {VaR}\")\n",
    "    print(f\"Conditional Value at Risk (CVaR): {CVaR}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
